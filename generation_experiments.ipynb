{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70fe9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# get the absolute path of the current script\n",
    "current_dir = \"/import/nlp/social_media_timeline_dashboard/\"\n",
    "\n",
    "# add THVAE-summary in directory to look for modules\n",
    "thvae_dir = os.path.abspath(os.path.join(current_dir,\"THVAE-summary\"))\n",
    "if thvae_dir not in sys.path:\n",
    "    sys.path.insert(0, thvae_dir)\n",
    "\n",
    "from thvae.data_pipelines.assemblers import assemble_vocab_pipeline\n",
    "from thvae.data_pipelines.assemblers import assemble_train_pipeline, \\\n",
    "    assemble_eval_pipeline, assemble_vocab_pipeline, assemble_infer_pipeline\n",
    "from thvae.utils.helpers.io import get_rev_number\n",
    "from thvae.utils.helpers.run import gen_summs\n",
    "from transformers import BartTokenizer\n",
    "from thvae.utils.fields import InpDataF\n",
    "from mltoolkit.mldp.utils.tools import Vocabulary\n",
    "from thvae.utils.hparams import ModelHP, RunHP\n",
    "from thvae.modelling import ThVAE as Model\n",
    "from thvae.modelling.interfaces import IThVAE\n",
    "from mltoolkit.mlmo.utils.tools.annealing import KlCycAnnealing\n",
    "from thvae.utils.tools import SeqPostProcessor\n",
    "from thvae.utils.fields import ModelF\n",
    "from thvae.utils.constants import VOCAB_DEFAULT_SYMBOLS\n",
    "\n",
    "from mltoolkit.mlutils.helpers.paths_and_files import comb_paths, get_file_name\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from thvae.modelling.interfaces import IDevThVAE as IDev, IThVAE as IModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae65cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea51c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset in the right input format for THVAE\n",
    "# load posts\n",
    "user_id = \"tomorrowistomato\"\n",
    "post_ids = [\n",
    "        \"ialh84\",\n",
    "        \"iam4l5\",\n",
    "        \"ii04gh\",\n",
    "        \"iik5wz\",\n",
    "        \"ioou4c\",\n",
    "        \"iozs0z\",\n",
    "        \"iu7ufs\",\n",
    "        \"iusum0\",\n",
    "        \"iuuvc3\",\n",
    "        \"ixj0zx\",\n",
    "        \"iymeea\",\n",
    "        \"j2eb4i\",\n",
    "        \"j3dkjk\",\n",
    "        \"j3pp6r\",\n",
    "        \"j72puw\",\n",
    "        \"j9j4nu\",\n",
    "        \"jawbob\"\n",
    "    ]\n",
    "\n",
    "THVAE_test_set = {\n",
    "    \"group_id\": [],\n",
    "    \"review_text\": [],\n",
    "    \"category\": [],\n",
    "}\n",
    "\n",
    "\n",
    "with open(f\"public/data/{user_id}_posts.json\", \"r\") as f:\n",
    "    posts = json.load(f)\n",
    "\n",
    "for post_id in post_ids:\n",
    "    THVAE_test_set[\"group_id\"].append(post_id)\n",
    "    THVAE_test_set[\"review_text\"].append(f\"{posts[post_id]['title']}\\n{posts[post_id]['body']}\")\n",
    "    THVAE_test_set[\"category\"].append(\"post\")\n",
    "\n",
    "test_set_df = pd.DataFrame(THVAE_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e17d9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_df.to_csv(\"thvae_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46708bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hp   = RunHP(root_path=os.path.join(current_dir, \"THVAE-summary\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5c8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp = ModelHP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d86e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c3517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data_source = {\"data_path\": run_hp.train_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88d25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PIPELINES AND VOCAB   #\n",
    "vocab_pipeline = assemble_vocab_pipeline(text_fname=InpDataF.REV_TEXT)\n",
    "word_vocab = Vocabulary(vocab_pipeline, name_prefix=\"word\")\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "\n",
    "# adding special symbols before creating vocab, so they would appear on top\n",
    "for st in VOCAB_DEFAULT_SYMBOLS:\n",
    "    if st not in word_vocab:\n",
    "        word_vocab.add_special_symbol(st)\n",
    "\n",
    "word_vocab.load_or_create(run_hp.words_vocab_fp,\n",
    "                          data_source=vocab_data_source,\n",
    "                          max_size=model_hp.ext_vocab_size, sep=' ',\n",
    "                          data_fnames=InpDataF.REV_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303f8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_pipeline = assemble_sum_pipeline(word_vocab,\n",
    "                                       bart_tokenizer=bart_tokenizer,\n",
    "                                       max_groups_per_batch=run_hp.val_max_groups_per_batch,\n",
    "                                       min_revs_per_group=run_hp.max_rev_per_group,\n",
    "                                       max_revs_per_group=run_hp.max_rev_per_group,\n",
    "                                       seed=run_hp.seed, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_summs(data_iter, output_file_path, summ_gen_func):\n",
    "    \"\"\"Generates summaries and saves them to a txt file. Order is preserved\"\"\"\n",
    "    out_file = open(output_file_path, encoding='utf-8', mode='w')\n",
    "    for batch in data_iter:\n",
    "        summs = summ_gen_func(batch)\n",
    "        for summ in summs:\n",
    "            out_file.write(summ + '\\n')\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_bsz = 40\n",
    "infer_inp_file_path = \"/import/nlp/social_media_timeline_dashboard/THVAE-summary/thvae/artifacts/amazon/data/infer_input.csv\"\n",
    "out_file_name = get_file_name(infer_inp_file_path)\n",
    "infer_out_file_path = comb_paths(run_hp.output_path,\n",
    "                                    f'{out_file_name}.out.txt')\n",
    "\n",
    "assert infer_inp_file_path is not None\n",
    "rev_num = get_rev_number(infer_inp_file_path)\n",
    "\n",
    "print(\"Performing inference/summary generation\")\n",
    "infer_data_pipeline = assemble_infer_pipeline(word_vocab, max_reviews=rev_num,\n",
    "                                                tokenization_func=run_hp.tok_func,\n",
    "                                                max_groups_per_chunk=infer_bsz)\n",
    "summ_pproc = SeqPostProcessor(tokenizer=lambda x: x.split(),\n",
    "                                detokenizer=run_hp.detok_func,\n",
    "                                tcaser=run_hp.true_case_func)\n",
    "\n",
    "print(f\"Saving summaries to: '{infer_out_file_path}'\")\n",
    "gen_summs(infer_data_pipeline.iter(data_path=infer_inp_file_path),\n",
    "            output_file_path=infer_out_file_path,\n",
    "            summ_gen_func=partial(idev.summ_generator,\n",
    "                                summ_post_proc=summ_post_proc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
